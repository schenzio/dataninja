{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "es_dataninja.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTN9EIbLWRRfL2tz7he6oD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schenzio/dataninja/blob/main/es_dataninja.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG5RCjkuR2Ve"
      },
      "source": [
        "# #datajournalism\n",
        "Questo programma usa l'API di Twitter per scaricare i tweets in lingua italiana degli ultimi due giorni con hashtag #datajournalism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlsYTfWZXhDV"
      },
      "source": [
        "Per prima cosa, inizializzo i parametri che userò per la configurazione dell'API (valori dell'app che ho creato con il mio account twitter sviluppatore) e scarico le librerie che mi servono:\n",
        "\n",
        "\n",
        "*   tweepy: per usare l'API di Twitter\n",
        "*   datetime: per accedere alle date\n",
        "*   pandas: per trattare i dati scaricati\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0UnpQ5MEssz"
      },
      "source": [
        "TWITTER_CONSUMER_KEY = 'F2NzdClQi2pdJCvjhTOSuROW3'\n",
        "TWITTER_CONSUMER_SECRET = 'tzCFQZH0ozxLCjzbrYB9HwNXcR7A7U2QLLPIFDAGf7ZrSFzBlI'\n",
        "TWITTER_ACCESS_TOKEN = '1332608230862823424-FakujOqx4M6TRk0pLfD8iIkfj6joex'\n",
        "TWITTER_ACCESS_TOKEN_SECRET = '2BaMf3EpXzFr8hyT0kBE4slJxIt4eHVtXoVEqqqn0bsNq'\n",
        "import tweepy\n",
        "import datetime\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P3MX9HMR0l9"
      },
      "source": [
        "Configuro la connessione alla mia app, accedo con i miei token e mi connetto alla Twitter API "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKU7MY_FqTr"
      },
      "source": [
        "auth = tweepy.OAuthHandler(TWITTER_CONSUMER_KEY, TWITTER_CONSUMER_SECRET)\n",
        "auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET)\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FIME86vgV6T"
      },
      "source": [
        "Salvo le date di ieri e oggi che specificherò in parametro alla query di ricerca dei tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMpkZ7bugEC9",
        "outputId": "0ab0e0e7-fbbf-4c7a-ae88-d45622e39a1d"
      },
      "source": [
        "today = datetime.date.today()\n",
        "yesterday = today - datetime.timedelta(days=1)\n",
        "print(\"il periodo di produzione dei tweets scaricati è:\", str(yesterday), \" - \", str(today))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "il periodo di produzione dei tweets scaricati è: 2021-05-03  -  2021-05-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwA1MpeFg4za"
      },
      "source": [
        "Scarico con la funzione Cursor i tweets che rispondon alle specifiche: #datajournalism, periodo tra ieri e oggi, lingua italiana"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bugc9yHMIhjN"
      },
      "source": [
        "tweets_list = tweepy.Cursor(api.search, q=\"#datajournalism since:\" + str(one_week_ago)+ \" until:\" + str(today),tweet_mode='extended', lang='it').items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ahJHV6kk9ST"
      },
      "source": [
        "Scorro i tweets scaricati e per ciascuno salvo i metadati di interesse (autore, testo, like, retweet, data) in un oggetto che inserisco nella lista output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-J48EZClX2I"
      },
      "source": [
        "output = []\n",
        "for tweet in tweets_list:\n",
        "  text = tweet._json[\"full_text\"]\n",
        "  favourite_count = tweet.favorite_count\n",
        "  retweet_count = tweet.retweet_count\n",
        "  created_at = tweet.created_at \n",
        "  author = tweet.user.name\n",
        "  line = {'author': author, 'text' : text, 'favourite_count' : favourite_count, 'retweet_count' : retweet_count, 'created_at' : created_at}\n",
        "  output.append(line)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky5bDr8bldh4"
      },
      "source": [
        "Converto output in un dataframe e lo visualizzo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpideudOljd3"
      },
      "source": [
        "df = pd.DataFrame(output)\n",
        "df.to_csv(r'C:\\Users\\Matteo\\Desktop\\export_dataframe.csv‘\\File Name.csv', index = False, header=True)"
      ],
      "execution_count": 101,
      "outputs": []
    }
  ]
}